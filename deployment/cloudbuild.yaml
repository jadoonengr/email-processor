# cloudbuild.yaml - Main Cloud Build configuration

# Build steps
steps:
  # Step: Install dependencies and run tests
  - name: 'python:3.11-slim'
    entrypoint: 'bash'
    args:
      - '-c'
      - |
        pip install --no-cache-dir -r requirements.txt
        pip install pytest pytest-cov flake8 black
        
        # Code formatting check
        black --check --diff .
        
        # Linting
        flake8 . --count --select=E9,F63,F7,F82 --show-source --statistics
        
        # Run tests
        python -m pytest tests/ -v --cov=. --cov-report=term-missing
    id: 'test'

  # Step: Create BigQuery resources if they don't exist
  - name: 'gcr.io/google.com/cloudsdktool/cloud-sdk:latest'
    entrypoint: 'bash'
    args:
      - '-c'
      - |
        # Check and create dataset
        if ! bq show ${_PROJECT_ID}:${_DATASET_NAME} > /dev/null 2>&1; then
          echo "Creating BigQuery dataset: ${_DATASET_NAME}"
          bq mk --location=${_BQ_LOCATION} --dataset ${_PROJECT_ID}:${_DATASET_NAME}
        else
          echo "Dataset ${_DATASET_NAME} already exists"
        fi
        
        # Check and create table
        if ! bq show ${_PROJECT_ID}:${_DATASET_NAME}.${_TABLE_NAME} > /dev/null 2>&1; then
          echo "Creating BigQuery table: ${_TABLE_NAME}"
          bq mk --table ${_PROJECT_ID}:${_DATASET_NAME}.${_TABLE_NAME} schema/email_messages_schema.json
        else
          echo "Table ${_TABLE_NAME} already exists"
        fi
    id: 'setup-bigquery'

  # Step: Create Cloud Storage bucket if it doesn't exist
  - name: 'gcr.io/google.com/cloudsdktool/cloud-sdk:latest'
    entrypoint: 'bash'
    args:
      - '-c'
      - |
        if ! gsutil ls gs://${_BUCKET_NAME} > /dev/null 2>&1; then
          echo "Creating Cloud Storage bucket: ${_BUCKET_NAME}"
          gsutil mb -l ${_REGION} gs://${_BUCKET_NAME}
          
          # Set bucket permissions
          gsutil iam ch serviceAccount:${_SERVICE_ACCOUNT_EMAIL}:objectAdmin gs://${_BUCKET_NAME}
        else
          echo "Bucket ${_BUCKET_NAME} already exists"
        fi
    id: 'setup-storage'

  # Step: Create Pub/Sub topic and subscription if they don't exist
  - name: 'gcr.io/google.com/cloudsdktool/cloud-sdk:latest'
    entrypoint: 'bash'
    args:
      - '-c'
      - |
        # Create topic
        if ! gcloud pubsub topics describe ${_PUBSUB_TOPIC} > /dev/null 2>&1; then
          echo "Creating Pub/Sub topic: ${_PUBSUB_TOPIC}"
          gcloud pubsub topics create ${_PUBSUB_TOPIC}
          
          # Grant Gmail service account publish permissions
          gcloud pubsub topics add-iam-policy-binding ${_PUBSUB_TOPIC} \
            --member=serviceAccount:gmail-api-push@system.gserviceaccount.com \
            --role=roles/pubsub.publisher
        else
          echo "Topic ${_PUBSUB_TOPIC} already exists"
        fi
        
        # Create subscription
        if ! gcloud pubsub subscriptions describe ${_PUBSUB_SUBSCRIPTION} > /dev/null 2>&1; then
          echo "Creating Pub/Sub subscription: ${_PUBSUB_SUBSCRIPTION}"
          gcloud pubsub subscriptions create ${_PUBSUB_SUBSCRIPTION} --topic=${_PUBSUB_TOPIC}
        else
          echo "Subscription ${_PUBSUB_SUBSCRIPTION} already exists"
        fi
    id: 'setup-pubsub'

  # Step: Deploy the Cloud Function 
  - name: 'gcr.io/google.com/cloudsdktool/cloud-sdk:latest'
    entrypoint: 'bash'
    args:
      - '-c'
      - |
        gcloud functions deploy ${_FUNCTION_NAME} \
          --gen2 \
          --runtime=python311 \
          --source=. \
          --entry-point=${_ENTRY_POINT} \
          --trigger-topic=${_PUBSUB_TOPIC} \
          --region=${_REGION} \
          --service-account=${_SERVICE_ACCOUNT_EMAIL} \
          --set-env-vars=PROJECT_ID=${_PROJECT_ID},DATASET_NAME=${_DATASET_NAME},TABLE_NAME=${_TABLE_NAME},BUCKET_NAME=${_BUCKET_NAME} \
          --memory=1GB \
          --timeout=540s \
          --max-instances=5
    id: 'deploy-cloud-function'

  # Step: Run deployment verification tests
  - name: 'gcr.io/google.com/cloudsdktool/cloud-sdk:latest'
    entrypoint: 'bash'
    args:
      - '-c'
      - |
        echo "Running deployment verification..."
        
        # Test Pub/Sub function
        gcloud functions describe ${_FUNCTION_NAME} --region=${_REGION}
        
        echo "Deployment verification completed"
    id: 'verify-deployment'

# Substitution variables
substitutions:
  # Core settings
  _PROJECT_ID: 'alpine-comfort-470817-s8'
  _REGION: 'us-central1'
  _BQ_LOCATION: 'US'
  
  # Service account
  _SERVICE_ACCOUNT_EMAIL: 'email-notifier-dev-sa@alpine-comfort-470817-s8.iam.gserviceaccount.com'
  
  # BigQuery
  _DATASET_NAME: 'idp'
  _TABLE_NAME: 'gmail_raw_emails'
  
  # Cloud Storage
  _BUCKET_NAME: 'gmail-attachments-bucket-2fba'
  
  # Pub/Sub
  _PUBSUB_TOPIC: 'email-notifier'
  _PUBSUB_SUBSCRIPTION: 'email-notifier-sub'
  
  # Cloud Functions
  _FUNCTION_NAME: 'email-processor'
  _ENTRY_POINT: 'process_emails'
  _SECRET_NAME: 'gmail-token'

# Build options
options:
  # Use higher CPU for faster builds
  machineType: 'E2_HIGHCPU_8'
  
  # Enable detailed logging
  logging: CLOUD_LOGGING_ONLY
  
  # Use custom worker pool if available
  # pool:
  #   name: 'projects/${_PROJECT_ID}/locations/${_REGION}/workerPools/gmail-build-pool'

# Build timeout (set at root level)
timeout: '1200s'